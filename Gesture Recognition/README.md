This program uses the Berkeley Caffe library in order to perform gesture recognition on a livestream.

In this case, the program helps the user complete a 'Jumping Jack', by informing them once they have reached the correct
'Start' Position, correct 'Midway' Position and correct 'End' Position.

Here is a demo of the program in action:

--> https://youtu.be/NFWEDsQwOC8

"Start" Position:

![Jumping Jack Start](https://user-images.githubusercontent.com/37419003/196056015-fba9317c-c126-4bf3-bec8-6ad57d0d88bd.png)

"Midway Position":

![Jumping Jack Midway](https://user-images.githubusercontent.com/37419003/196056017-e427beb6-4f75-4503-9719-24ef07d530aa.png)

"End" Position:

![Jumping Jack End](https://user-images.githubusercontent.com/37419003/196056021-f8fd9299-0d31-4e0d-85ae-ac07f3a67174.png)
